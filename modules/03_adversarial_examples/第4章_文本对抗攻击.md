# 第 4 章：文本对抗攻击

**章节目标**
- 理解文本对抗攻击与图像对抗攻击的区别
- 掌握三种主要的文本攻击层次：字符级、词级、句级
- 了解文本对抗样本的生成方法
- 认识文本对抗攻击的实际应用场景

---

## 1. 文本对抗攻击的独特挑战（25%）

### 1.1 为什么文本攻击更难

图像对抗攻击可以对每个像素做微小调整，但文本是**离散**的：

| 对比维度 | 图像 | 文本 |
|---------|------|------|
| **数据类型** | 连续（像素值 0-255） | 离散（单词/字符） |
| **微调能力** | 可以改变 0.01 | 只能整词替换 |
| **梯度计算** | 直接可用 | 不可直接计算 |
| **感知约束** | 肉眼不可见的小扰动 | 必须保持可读性和语义 |

**核心困难**：你不能把 "apple" 改成 "appld"（这不是一个词），也不能做 "0.01 个词" 的修改。

### 1.2 文本对抗的目标

**攻击目标示例**：

| 任务 | 原始文本 | 对抗文本 | 目标 |
|-----|---------|---------|------|
| **情感分析** | "这部电影太棒了！" | "这部电影太棒了！"（微调） | 正面→负面 |
| **垃圾邮件检测** | "免费领取大奖" | "Frее领取大獎" | 垃圾→正常 |
| **有害内容检测** | "如何制造危险物" | "如何製造危險物" | 有害→无害 |

### 1.3 文本对抗的约束条件

好的文本对抗样本需要满足：

1. **语义保持**：意思基本不变
2. **语法正确**：读起来通顺
3. **拼写正确**：每个词都是真实的词
4. **人类可读**：不能太奇怪引起怀疑

### 1.4 攻击层次概览

```
┌─────────────────────────────────────────┐
│               句级攻击                   │
│        (重写整个句子，保持语义)           │
├─────────────────────────────────────────┤
│               词级攻击                   │
│        (替换同义词、关键词)              │
├─────────────────────────────────────────┤
│               字符级攻击                 │
│        (替换相似字符、添加拼写错误)       │
└─────────────────────────────────────────┘
```

---

## 2. 字符级攻击（25%）

### 2.1 字符级攻击原理

字符级攻击通过**微小的字符修改**来绕过检测，利用：
- 人类阅读时会自动纠错
- 机器检测往往依赖精确匹配

### 2.2 常见字符级技术

**同形字符替换（Homoglyph）**：

用外观相似但编码不同的字符替换：

```
原文：password
攻击：pаsswοrd
      ↑     ↑
   西里尔a  希腊o
```

**常用同形字符对照**：
| 拉丁字符 | 替代字符 | 来源 |
|---------|---------|------|
| a | а | 西里尔字母 |
| e | е | 西里尔字母 |
| o | ο | 希腊字母 |
| c | с | 西里尔字母 |

**拼写错误注入**：

故意引入人类容易忽略的拼写错误：

```
原文：definitely
攻击：definately（常见拼写错误，人类能理解）

原文：receive
攻击：recieve（i/e 顺序错误）
```

**字符插入/删除**：

```
原文：hello
攻击：hel​lo（插入零宽空格，肉眼不可见）

原文：attack
攻击：atttack（重复字符）
```

### 2.3 字符级攻击的效果

**优点**：
- 实现简单
- 对关键词过滤非常有效
- 人类几乎察觉不到

**缺点**：
- 对语义理解模型效果有限
- 可以通过文本规范化防御
- 大量使用会显得可疑

### 2.4 防御方法

```python
# 简化的字符规范化防御
def normalize_text(text):
    # 1. Unicode 规范化
    text = unicodedata.normalize('NFKC', text)

    # 2. 移除零宽字符
    text = remove_zero_width_chars(text)

    # 3. 同形字符映射
    text = map_homoglyphs_to_ascii(text)

    return text
```

---

## 3. 词级攻击（30%）

### 3.1 词级攻击原理

词级攻击通过**替换、删除或插入单词**来改变模型判断，同时保持句子的可读性和语义。

### 3.2 同义词替换攻击

最常用的词级攻击方法：

```
原文：This movie is excellent and I loved every minute.
攻击：This film is outstanding and I enjoyed every moment.
```

**替换策略**：
- 使用同义词词典（如 WordNet）
- 使用词向量找语义相近的词
- 优先替换对模型判断影响最大的词

### 3.3 关键词识别

不是所有词都值得替换。需要找到**对模型决策影响最大**的词：

```
"This movie is [excellent] and I [loved] every minute."
              ↑              ↑
           关键词          关键词

这些词对"正面情感"的判断贡献最大
```

**识别方法**：
1. 逐个删除每个词，看模型输出变化
2. 变化最大的词 = 最关键的词
3. 优先攻击这些词

### 3.4 TextFooler 算法

TextFooler 是经典的词级攻击算法：

```
输入：原始文本、目标模型
输出：对抗文本

步骤 1：计算每个词的重要性分数
步骤 2：按重要性排序
步骤 3：对每个重要词：
        ├─ 找到语义相似的候选替换词
        ├─ 用每个候选词替换，查询模型
        └─ 选择让模型最"困惑"的替换
步骤 4：重复直到攻击成功或无词可换
```

### 3.5 词级攻击示例

**情感分析攻击**：

| 原文 | 对抗文本 | 原判断 | 对抗判断 |
|-----|---------|-------|---------|
| "The food was **delicious**" | "The food was **tasty**" | 正面 95% | 正面 60% |
| "I **hate** this product" | "I **despise** this product" | 负面 90% | 负面 45% |
| "**Excellent** service!" | "**Outstanding** service!" | 正面 92% | 正面 51% |

### 3.6 词级攻击的挑战

**语义漂移**：替换词可能微妙地改变含义
```
"She is slim" → "She is skinny"（语义略有变化）
```

**语法错误**：替换后可能语法不通
```
"He runs fast" → "He running fast"（语法错误）
```

**上下文不匹配**：
```
"Apple released a new phone"
→ "Apple released a new telephone"（telephone 不自然）
```

---

## 4. 句级攻击（15%）

### 4.1 句级攻击原理

句级攻击**重写整个句子**，保持语义但改变表达方式。这是最难检测的攻击。

### 4.2 回译攻击（Back-Translation）

利用机器翻译的"创造性"：

```
原文（中文）：这个产品质量很差
     ↓ 翻译成英文
     "This product is of poor quality"
     ↓ 翻译回中文
回译结果：这款产品的品质不佳
```

经过回译，表达方式改变了，但意思相同。

### 4.3 改写攻击（Paraphrase）

使用改写模型生成语义相同但表达不同的句子：

```
原文："I really enjoyed watching this film."
改写1："This movie was quite enjoyable to watch."
改写2："Watching this film was a pleasant experience."
改写3："I had a great time with this movie."
```

### 4.4 句级攻击的特点

**优点**：
- 生成的文本最自然
- 最难被检测
- 语义保持最好

**缺点**：
- 需要复杂的改写模型
- 计算成本高
- 不能精确控制攻击效果

---

## 5. 文本对抗攻击的应用场景（5%）

### 5.1 攻击场景

| 场景 | 攻击目标 | 攻击方法 |
|-----|---------|---------|
| **绕过垃圾邮件过滤** | 让垃圾邮件不被拦截 | 字符替换、同义词 |
| **绕过有害内容检测** | 让违规内容不被发现 | 词级替换、改写 |
| **欺骗情感分析** | 操纵评论分析结果 | 词级攻击 |
| **规避抄袭检测** | 让抄袭内容通过检查 | 句级改写 |

### 5.2 防御思路

1. **输入规范化**：处理同形字符、特殊编码
2. **对抗训练**：用对抗样本增强模型鲁棒性
3. **集成检测**：多个模型投票，降低单点失败风险
4. **语义验证**：检查输入的语义一致性

---

## 本章小结

### 核心要点回顾

1. **文本攻击的挑战**：离散性导致无法直接用梯度方法
2. **三个攻击层次**：
   - 字符级：同形字符、拼写错误
   - 词级：同义词替换、关键词攻击
   - 句级：回译、改写
3. **约束条件**：语义保持、语法正确、人类可读
4. **防御思路**：输入规范化 + 对抗训练 + 多模型集成

### 与实验的衔接

在 **实验 3.4：文本对抗攻击** 中，你将：
- 实现简单的同义词替换攻击
- 观察不同替换策略的攻击效果
- 体验词重要性评估方法

---

## 课后思考题

1. **理解性问题**：为什么字符级攻击对基于关键词的过滤器很有效，但对深度学习模型效果有限？

2. **分析性问题**：词级攻击中，为什么需要先识别"重要词"再进行替换？随机替换会有什么问题？

3. **设计性问题**：如果你要设计一个鲁棒的垃圾邮件检测系统，如何同时防御字符级、词级和句级攻击？

---

## 扩展阅读

- **TextFooler 论文**：《Is BERT Really Robust?》
- **文本对抗综述**：《Adversarial Attacks on Text: A Survey》
- **对抗训练**：《FreeLB: Enhanced Adversarial Training for Natural Language Understanding》

---

**法律与伦理提醒**：
文本对抗技术可用于测试内容审核系统的鲁棒性，但不应用于绕过正当的安全检测。使用这些技术发布有害内容或进行欺诈是违法的。
