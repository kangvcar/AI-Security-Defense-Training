{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验 4.1：训练数据提取\n",
    "\n",
    "## 实验目标\n",
    "- 理解语言模型的\"记忆\"现象\n",
    "- 体验基于补全的训练数据提取攻击\n",
    "- 观察不同提示对提取效果的影响\n",
    "\n",
    "## 实验环境\n",
    "- Python 3.8+\n",
    "- transformers（GPT-2 模型）\n",
    "\n",
    "## 预计时间：25 分钟\n",
    "\n",
    "---\n",
    "\n",
    "## 核心概念回顾\n",
    "语言模型可能会\"记住\"训练数据中的特定内容。通过精心设计的提示，可能诱导模型输出这些记忆内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一部分：环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# 设置中文显示\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"正在加载 GPT-2 模型...\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model.eval()\n",
    "print(\"模型加载完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义文本生成函数\n",
    "def generate_text(prompt, max_length=50, num_return=1, temperature=1.0):\n",
    "    \"\"\"\n",
    "    根据提示生成文本\n",
    "    \n",
    "    参数：\n",
    "        prompt: 输入提示\n",
    "        max_length: 最大生成长度\n",
    "        num_return: 返回几个生成结果\n",
    "        temperature: 温度参数（越低越确定性）\n",
    "    \"\"\"\n",
    "    inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=num_return,\n",
    "            temperature=temperature,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    results = []\n",
    "    for output in outputs:\n",
    "        text = tokenizer.decode(output, skip_special_tokens=True)\n",
    "        results.append(text)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 测试生成函数\n",
    "test_result = generate_text(\"Hello, my name is\", max_length=20)\n",
    "print(f\"测试生成：{test_result[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二部分：计算困惑度（Perplexity）\n",
    "\n",
    "困惑度衡量模型对一段文本的\"熟悉程度\"：\n",
    "- 困惑度低 = 模型很熟悉（可能是训练数据）\n",
    "- 困惑度高 = 模型不熟悉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 【填空 1】实现困惑度计算函数\n",
    "# 提示：困惑度 = exp(平均交叉熵损失)\n",
    "# 参考答案见下方\n",
    "\n",
    "def calculate_perplexity(text):\n",
    "    \"\"\"\n",
    "    计算文本的困惑度\n",
    "    困惑度越低，说明模型对这段文本越\"熟悉\"\n",
    "    \"\"\"\n",
    "    # 编码文本\n",
    "    inputs = tokenizer.encode(text, return_tensors='pt')\n",
    "    \n",
    "    # 计算损失\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs, labels=inputs)\n",
    "        loss = outputs.loss.item()  # 平均交叉熵损失\n",
    "    \n",
    "    # 【填空 1】计算困惑度\n",
    "    # 提示：perplexity = np.exp(loss)\n",
    "    # 参考答案：perplexity = np.exp(loss)\n",
    "    perplexity = ___________________\n",
    "    \n",
    "    return perplexity\n",
    "\n",
    "# 测试\n",
    "test_texts = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",  # 常见句子\n",
    "    \"Xkcd qwerty asdfgh zxcvbn random keyboard.\",    # 随机内容\n",
    "]\n",
    "\n",
    "print(\"困惑度测试：\")\n",
    "for text in test_texts:\n",
    "    ppl = calculate_perplexity(text)\n",
    "    print(f\"  '{text[:40]}...' → 困惑度: {ppl:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第三部分：基于补全的提取攻击"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 【填空 2】设计可能触发记忆的提示\n",
    "# 提示：使用常见的格式化模板，如邮箱、电话等\n",
    "# 参考答案见下方\n",
    "\n",
    "# 这些提示模拟可能在训练数据中出现的格式\n",
    "extraction_prompts = [\n",
    "    # 参考答案：\n",
    "    # \"My email address is\",\n",
    "    # \"Contact me at\",\n",
    "    # \"Phone number:\",\n",
    "    ___________________,\n",
    "    \"My email address is\",\n",
    "    \"The password is\",\n",
    "]\n",
    "\n",
    "print(\"尝试提取可能的训练数据...\\n\")\n",
    "for prompt in extraction_prompts:\n",
    "    if prompt:  # 跳过空的填空\n",
    "        print(f\"提示: '{prompt}'\")\n",
    "        completions = generate_text(prompt, max_length=30, num_return=3, temperature=0.7)\n",
    "        for i, comp in enumerate(completions, 1):\n",
    "            # 只显示生成的部分\n",
    "            generated = comp[len(prompt):].strip()\n",
    "            print(f\"  补全 {i}: {generated[:50]}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析生成内容的困惑度\n",
    "# 低困惑度的生成内容更可能来自训练数据\n",
    "\n",
    "def extraction_attack(prompt, num_samples=5):\n",
    "    \"\"\"\n",
    "    执行提取攻击，并按困惑度排序结果\n",
    "    \"\"\"\n",
    "    completions = generate_text(prompt, max_length=40, num_return=num_samples, temperature=1.0)\n",
    "    \n",
    "    results = []\n",
    "    for comp in completions:\n",
    "        ppl = calculate_perplexity(comp)\n",
    "        results.append((comp, ppl))\n",
    "    \n",
    "    # 按困惑度排序（低到高）\n",
    "    results.sort(key=lambda x: x[1])\n",
    "    return results\n",
    "\n",
    "# 测试\n",
    "print(\"提取攻击结果（按困惑度排序，低困惑度更可疑）：\\n\")\n",
    "prompt = \"The CEO of Apple is\"\n",
    "results = extraction_attack(prompt, num_samples=5)\n",
    "\n",
    "print(f\"提示: '{prompt}'\")\n",
    "print(\"-\" * 60)\n",
    "for text, ppl in results:\n",
    "    generated = text[len(prompt):].strip()\n",
    "    print(f\"困惑度 {ppl:6.2f}: {generated[:50]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第四部分：记忆与泛化的区别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 【填空 3】对比\"记忆\"和\"泛化\"的困惑度\n",
    "# 提示：著名文本片段通常有更低的困惑度\n",
    "\n",
    "# 可能被\"记住\"的著名文本\n",
    "memorized_texts = [\n",
    "    \"To be, or not to be, that is the question.\",  # 莎士比亚\n",
    "    \"Four score and seven years ago\",               # 林肯\n",
    "    \"I have a dream that one day\",                  # 马丁路德金\n",
    "]\n",
    "\n",
    "# 新创作的、不太可能在训练集中的文本\n",
    "novel_texts = [\n",
    "    \"The purple elephant danced on the rainbow bridge.\",\n",
    "    \"My favorite breakfast is quantum physics with toast.\",\n",
    "    \"The robot decided to become a professional cloud painter.\",\n",
    "]\n",
    "\n",
    "print(\"记忆 vs 泛化 - 困惑度对比\\n\")\n",
    "\n",
    "# 【填空 3】计算并对比两类文本的困惑度\n",
    "# 参考答案：\n",
    "# mem_ppls = [calculate_perplexity(t) for t in memorized_texts]\n",
    "# nov_ppls = [calculate_perplexity(t) for t in novel_texts]\n",
    "\n",
    "mem_ppls = ___________________\n",
    "nov_ppls = [calculate_perplexity(t) for t in novel_texts]\n",
    "\n",
    "print(\"著名文本（可能被记忆）：\")\n",
    "for text, ppl in zip(memorized_texts, mem_ppls):\n",
    "    print(f\"  困惑度 {ppl:6.2f}: {text[:40]}...\")\n",
    "\n",
    "print(\"\\n新创文本（需要泛化）：\")\n",
    "for text, ppl in zip(novel_texts, nov_ppls):\n",
    "    print(f\"  困惑度 {ppl:6.2f}: {text[:40]}...\")\n",
    "\n",
    "print(f\"\\n平均困惑度 - 著名文本: {np.mean(mem_ppls):.2f}, 新创文本: {np.mean(nov_ppls):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化对比\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "x = np.arange(3)\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, mem_ppls, width, label='著名文本（可能被记忆）', color='coral')\n",
    "plt.bar(x + width/2, nov_ppls, width, label='新创文本（需要泛化）', color='steelblue')\n",
    "\n",
    "plt.xlabel('样本')\n",
    "plt.ylabel('困惑度')\n",
    "plt.title('记忆 vs 泛化：困惑度对比\\n（低困惑度 = 模型更\"熟悉\"）')\n",
    "plt.xticks(x, ['样本1', '样本2', '样本3'])\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"观察：著名文本通常有更低的困惑度，说明模型对它们更'熟悉'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第五部分：温度参数对提取的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试不同温度对生成内容的影响\n",
    "temperatures = [0.5, 1.0, 1.5]\n",
    "test_prompt = \"The capital of France is\"\n",
    "\n",
    "print(f\"提示: '{test_prompt}'\\n\")\n",
    "print(\"不同温度的生成效果：\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for temp in temperatures:\n",
    "    completions = generate_text(test_prompt, max_length=25, num_return=3, temperature=temp)\n",
    "    print(f\"\\n温度 = {temp}:\")\n",
    "    for comp in completions:\n",
    "        generated = comp[len(test_prompt):].strip()\n",
    "        ppl = calculate_perplexity(comp)\n",
    "        print(f\"  [困惑度 {ppl:.1f}] {generated[:40]}\")\n",
    "\n",
    "print(\"\\n观察：低温度 → 更确定性的输出 → 更可能输出训练数据中的内容\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验总结\n",
    "\n",
    "### 观察记录\n",
    "\n",
    "请回答以下问题：\n",
    "\n",
    "1. **困惑度与记忆的关系是什么？** 低困惑度的文本是否更可能来自训练数据？\n",
    "\n",
    "2. **什么类型的提示更容易触发记忆？** 格式化模板（如邮箱、电话）为什么有效？\n",
    "\n",
    "3. **温度参数如何影响提取？** 低温度和高温度的生成有什么区别？\n",
    "\n",
    "### 核心概念回顾\n",
    "\n",
    "- **记忆现象**：模型可能逐字记住部分训练数据\n",
    "- **困惑度**：衡量模型对文本的熟悉程度\n",
    "- **提取攻击**：通过提示诱导模型输出记忆内容\n",
    "- **温度参数**：影响生成的随机性和确定性\n",
    "\n",
    "---\n",
    "\n",
    "**下一个实验**：实验 4.2 成员推理攻击"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
