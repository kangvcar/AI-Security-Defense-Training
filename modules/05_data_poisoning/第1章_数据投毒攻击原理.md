# 第 1 章：数据投毒攻击原理

**章节目标**
- 理解数据投毒攻击的基本概念和危害
- 掌握标签翻转攻击的原理和实现
- 了解干净标签攻击的隐蔽性
- 认识数据投毒与对抗样本的区别

---

## 1. 什么是数据投毒（25%）

### 1.1 数据投毒的定义

数据投毒（Data Poisoning）是指攻击者通过**污染训练数据**，使得训练出的模型产生攻击者期望的错误行为。

```
正常流程：干净数据 → 训练 → 正常模型

投毒流程：干净数据 + 毒化数据 → 训练 → 被污染的模型
                ↑
           攻击者注入
```

### 1.2 生活化类比

**类比一：在食材里下毒**

想象一个餐厅的厨师（模型）通过品尝食材（训练数据）来学习烹饪。如果有人在食材里掺入了有害物质，厨师学到的"技能"就会出问题——他可能学会做出有毒的菜。

**类比二：教科书篡改**

如果有人悄悄修改了学生的教科书，把错误的知识写进去，学生（模型）就会学到错误的内容。而且这种错误是"从根源上"造成的，很难发现。

### 1.3 数据投毒 vs 对抗样本

| 对比维度 | 对抗样本 | 数据投毒 |
|---------|---------|---------|
| **攻击时机** | 推理阶段（模型已部署） | 训练阶段（模型训练前） |
| **攻击目标** | 欺骗已有模型 | 污染模型学习过程 |
| **持久性** | 临时（每次需要新样本） | 持久（模型一直有问题） |
| **隐蔽性** | 攻击样本可能被检测 | 污染可能完全不可见 |
| **修复难度** | 加强输入检测 | 需要重新训练模型 |

### 1.4 数据投毒的危害

| 攻击场景 | 危害描述 |
|---------|---------|
| **垃圾邮件过滤** | 让正常邮件被误判为垃圾 |
| **恶意软件检测** | 让恶意软件逃过检测 |
| **自动驾驶** | 让模型误判交通标志 |
| **推荐系统** | 操纵推荐结果 |
| **金融风控** | 让欺诈交易通过检测 |

---

## 2. 标签翻转攻击（30%）

### 2.1 标签翻转的原理

标签翻转攻击（Label Flipping Attack）是最简单的数据投毒方式：**故意给数据标注错误的标签**。

```
正常数据：
  图片A（猫）→ 标签：猫 ✓
  图片B（狗）→ 标签：狗 ✓

投毒数据：
  图片A（猫）→ 标签：狗 ✗（故意标错）
  图片B（狗）→ 标签：猫 ✗（故意标错）
```

### 2.2 攻击者的能力假设

| 攻击者能力 | 说明 |
|-----------|------|
| **完全控制** | 可以任意修改部分训练数据 |
| **众包渗透** | 作为标注员混入众包平台 |
| **数据源污染** | 污染公开数据集 |

### 2.3 标签翻转的效果

**投毒比例与影响**：

| 投毒比例 | 模型准确率下降 | 隐蔽性 |
|---------|--------------|-------|
| 1% | 轻微 | 极高 |
| 5% | 明显 | 高 |
| 10% | 严重 | 中等 |
| 20%+ | 模型基本不可用 | 低 |

**关键发现**：即使只污染 1-5% 的数据，也能显著影响模型性能。

### 2.4 目标攻击 vs 无目标攻击

**无目标攻击（Untargeted）**：
- 目的：让模型整体性能下降
- 方法：随机翻转标签
- 效果：模型准确率降低

**目标攻击（Targeted）**：
- 目的：让模型对特定类别产生错误
- 方法：只翻转特定类别的标签
- 效果：模型在特定类别上失效

**示例**：
```
目标：让模型把"狗"误判为"猫"

投毒策略：
- 收集所有"狗"的图片
- 把标签改成"猫"
- 混入训练集

结果：模型学会把狗的特征和"猫"这个标签关联
```

### 2.5 案例：众包标注投毒

**场景**：
许多公司使用众包平台（如 Amazon Mechanical Turk）进行数据标注。

**攻击方式**：
1. 攻击者注册成为标注员
2. 故意给部分数据标注错误标签
3. 这些错误标签混入训练数据

**真实研究**：
研究人员发现，在众包平台上：
- 5-10% 的标注员可能是恶意的或不认真的
- 没有质量控制时，标签错误率可达 10-20%
- 恶意标注员可以通过策略性标错绕过质量检测

---

## 3. 干净标签攻击（25%）

### 3.1 为什么需要干净标签攻击

标签翻转攻击有一个弱点：**标签明显错误，容易被人工审核发现**。

干净标签攻击（Clean-Label Attack）解决了这个问题：**数据和标签看起来都是正确的**，但仍然能污染模型。

### 3.2 干净标签攻击的原理

核心思想：不改变标签，而是**微调数据本身**，使其在特征空间中产生误导。

```
正常样本：猫图片 → 标签：猫 → 模型学习猫的特征

干净标签投毒：
  特殊处理的猫图片 → 标签：猫（正确！）
                    ↓
  但图片被添加了隐藏的"狗特征"
                    ↓
  模型学习时会把这些特征和"猫"关联
                    ↓
  结果：真正的狗可能被误判为猫
```

### 3.3 特征碰撞攻击

**方法**：
1. 选择一个目标样本（如攻击者的人脸）
2. 选择一个基础样本（如某个授权用户的人脸）
3. 对基础样本添加扰动，使其在特征空间中接近目标样本
4. 用正确的标签（授权用户）将其加入训练集
5. 模型学会把目标样本的特征和授权用户关联

**结果**：攻击者的人脸可以通过人脸识别系统。

### 3.4 干净标签 vs 标签翻转

| 对比维度 | 标签翻转 | 干净标签 |
|---------|---------|---------|
| **标签修改** | 是 | 否 |
| **数据修改** | 否 | 是（微小） |
| **可检测性** | 标签审核可发现 | 非常难发现 |
| **攻击难度** | 简单 | 复杂 |
| **需要的知识** | 无 | 需要了解模型 |

### 3.5 干净标签攻击的隐蔽性

为什么干净标签攻击难以检测：

1. **标签正确**：人工审核不会发现问题
2. **图片看似正常**：扰动对人眼不可见
3. **统计特征正常**：不会触发异常检测
4. **效果延迟**：只有特定输入才会触发错误

---

## 4. 投毒攻击的实施条件（20%）

### 4.1 攻击者需要什么

| 条件 | 必要性 | 说明 |
|-----|-------|------|
| **数据注入能力** | 必须 | 能向训练集添加数据 |
| **目标模型知识** | 可选 | 知道模型结构可优化攻击 |
| **训练过程控制** | 可选 | 控制训练可保证投毒效果 |

### 4.2 常见的投毒入口

**入口一：公开数据集**
- 许多模型使用公开数据集训练
- 攻击者可以尝试污染这些数据集
- 案例：研究人员证明可以向 Wikipedia 注入恶意内容

**入口二：用户上传数据**
- 推荐系统使用用户行为数据
- 恶意用户可以制造虚假行为
- 案例：评分操纵、点击欺诈

**入口三：众包标注**
- 前面已讨论
- 恶意标注员可以注入错误标签

**入口四：供应链**
- 使用第三方预训练模型
- 第三方模型可能已被投毒
- 下一章详细讨论

### 4.3 投毒检测的挑战

为什么数据投毒难以检测：

1. **规模问题**：训练集可能有百万样本，难以逐一检查
2. **隐蔽设计**：高级攻击专门设计来逃避检测
3. **延迟效应**：投毒效果可能在特定条件下才显现
4. **缺乏基准**：不知道"干净"数据应该是什么样

---

## 本章小结

### 核心要点回顾

1. **数据投毒的本质**：通过污染训练数据，从根源上破坏模型
2. **标签翻转攻击**：简单但容易被发现，修改标签
3. **干净标签攻击**：隐蔽但复杂，修改数据特征
4. **持久性危害**：投毒效果持续存在，直到模型重新训练

### 与实验的衔接

在 **实验 5.1：标签翻转攻击** 中，你将：
- 实现简单的标签翻转投毒
- 观察不同投毒比例对模型准确率的影响
- 理解投毒攻击的实际效果

---

## 课后思考题

1. **理解性问题**：为什么数据投毒比对抗样本攻击更难防御？从攻击时机和持久性角度分析。

2. **分析性问题**：干净标签攻击为什么比标签翻转攻击更难检测？攻击者需要什么额外的知识？

3. **设计性问题**：如果你负责一个使用众包标注的机器学习项目，你会设计什么机制来防止恶意标注？

---

## 扩展阅读

- **投毒攻击综述**：《Poisoning Attacks against Machine Learning: A Survey》
- **干净标签攻击**：Shafahi et al.《Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks》
- **众包安全**：《Adversarial Crowdsourcing Through Robust Rank-One Matrix Completion》

---

**法律与伦理提醒**：
数据投毒攻击可能导致严重的安全事故。本章内容用于理解攻击原理，帮助设计更安全的数据收集和训练流程。未经授权对他人的训练数据进行投毒是违法行为。
