# GenAI 安全攻防实训教程 - 课程设计规范总结

## 项目背景
将英文 GenAI Security 项目改编为适合中国大专（高职）大二学生的中文实训教程。

## 学生背景
- 大二学生
- 具备 Python 基础
- 少量机器学习概念
- 目标：自主学习能力培养

---

## 一、实验设计规范（已确认）

### 1. 核心原则
- **极简依赖**：只使用 transformers, torch, numpy, matplotlib（≤4 个核心库）
- **代码精简**：每个实验总代码量 ≤ 40 行，学生填空 ≤ 5 处
- **填空标准化**：每个填空 1-2 行，必须提供【提示】和【参考答案】
- **自学友好**：详细中文注释，解释"为什么"而非"怎么做"

### 2. 填空设计标准

**标准格式**：
```python
# 【填空 X】任务描述
# 提示：具体的实现提示
# 参考答案：完整的答案代码
变量名 = ___________________
```

**难度分级**：
- ⭐ 简单：直接调用函数，1 个参数
- ⭐⭐ 中等：调用函数，2-3 个参数
- ⭐⭐⭐ 较难：简单表达式或逻辑

**禁止的填空类型**：
- ❌ 需要理解复杂算法
- ❌ 需要查阅 API 文档
- ❌ 需要数学推导
- ❌ 超过 2 行代码的填空

### 3. 实验自查清单
- [ ] 代码总量 ≤ 40 行（含注释）
- [ ] 填空数量 ≤ 5 个
- [ ] 每个填空提供【提示】和【参考答案】
- [ ] 外部依赖 ≤ 4 个库
- [ ] 运行时间 ≤ 5 分钟（天池 CPU 环境）
- [ ] 核心概念用注释解释清楚
- [ ] 观察问题明确且可回答
- [ ] 无需提交报告，现场验收即可

### 4. 注释要求
- **每行关键代码必须配中文注释**
- 注释解释"为什么这么写"，而非"这是什么"
- 复杂逻辑需要分步注释
- 函数参数的含义必须注释

### 5. 实验目标
- 主要目标：**观察现象、理解原理**
- 次要目标：填空完成代码
- 不要求：编写大段代码、产出报告

### 6. 实验平台与依赖管理

**实验平台**：腾讯 Cloud Studio（https://cloudstudio.net/）
- 提供免费 NVIDIA T4 GPU（16GB 显存）
- 支持 Jupyter Notebook 环境
- 国内访问速度快，模型下载稳定

**硬件配置**：
- GPU：NVIDIA Tesla T4（16GB 显存）
- 适合运行 ≤7B 参数的模型

**必需依赖**：
```python
transformers==4.40.0
torch==2.1.0
numpy==1.24.3
matplotlib==3.7.1
accelerate==0.27.0  # GPU 加速
```

**推荐模型列表**：
```python
MODELS = {
    # 模块一、二：对话与提示词攻击实验
    "chat": "Qwen/Qwen2-1.5B-Instruct",  # 中文优秀，有安全护栏

    # 模块三：文本对抗攻击
    "text_classification": "hfl/chinese-macbert-base",  # 最强中文BERT

    # 模块三：图像对抗攻击
    "image_classification": "torchvision.models.resnet18",

    # 模块四：训练数据提取
    "text_generation": "uer/gpt2-chinese-cluecorpussmall",  # 中文GPT-2

    # 模块四、五：简单分类任务
    "simple_classifier": "自定义 PyTorch 网络",
}
```

**模型选择理由**：
| 模型 | 用途 | 显存占用 | 选择理由 |
|------|------|---------|---------|
| Qwen2-1.5B-Instruct | 对话、注入实验 | ~4GB | 中文顶级，有安全护栏 |
| chinese-macbert-base | 文本分类 | ~1.5GB | 最强中文BERT变体 |
| resnet18 | 图像分类 | <1GB | 经典、快速、易理解 |
| gpt2-chinese | 数据提取 | ~1GB | 小模型易观察记忆效应 |

**去掉的不稳定依赖**：
- ❌ Garak（改为手动测试）
- ❌ TextAttack（改为硬编码同义词）
- ❌ NLTK WordNet（改为预设词表）
- ❌ sklearn 的复杂算法（改为简单逻辑）

---

## 二、理论部分规范（已确认）

### 1. 整体要求
- **难度控制**：所有模块控制在初级水平（⭐ 到 ⭐⭐）
- **避免晦涩公式**：用通俗语言解释，保持专业性
- **篇幅充实**：每章 4000-5000 字，确保讲解透彻、循序渐进
- **教学风格统一**：类比教学 + 案例驱动 + 渐进式讲解
- **学生视角**：站在学生学习理解的角度编写，提供详细的解释
- **内容**：要求具有规范的标题结构，每个小节标题清晰，内容逻辑清晰，有出版书籍的标准。
- **教程风格**：友好型，引导型，避免生硬的命令式口吻。

### 2. 章节结构标准

**每章必备要素**：
1. **章节目标**（3-5 个）
2. **主要内容**（4-5 个小节，比例分配明确）
3. **教学资源**（案例、图表、视频）
4. **课后思考题**（3 个）

**内容分配比例**（仅供内部参考，不在正文中显示）：
- 概念引入：20-25%
- 原理讲解：35-40%
- 案例分析：20-25%
- 应用场景：10-15%

### 3. 教学方法

**学生视角优先**：
- 站在学生学习理解的角度编写内容
- 预测学生在每个知识点可能遇到的困惑提供详细的解释
- 主动补充必要的背景知识和前置概念
- 循序渐进，不跳跃，确保知识链条完整
- 多问"学生此时会想什么？会有什么疑问？"

**类比教学**：
- 每个复杂概念都有生动的生活化类比

**案例驱动**：
- 每章至少 1 个真实案例
- 案例包含：背景、攻击手法、影响、应对措施
- 优先选择国内外知名事件

**渐进式讲解**：
- 直觉理解 → 原理解释 → 技术细节
- 避免一开始就讲技术实现
- 用图示辅助理解
- 每引入一个新概念，先解释"为什么需要了解这个"

### 4. 术语处理
- 首次出现：中英文对照
- 示例：提示词注入（Prompt Injection）
- 建立术语对照表

### 5. 公式处理原则
- **能不用就不用**
- 必须用时：先用文字解释直觉，再给公式
- 复杂公式：拆解为多个步骤
- 提供"无公式版"解释

---

## 三、课程结构（已确认）

### 模块总览

| 模块 | 章节数 | 理论学时 | 实验学时 | 难度 |
|------|-------|---------|---------|------|
| 模块一：AI 安全基础 | 5 章 | 6 学时 | 4 学时 | ⭐ |
| 模块二：提示词攻击 | 5 章 | 8 学时 | 6 学时 | ⭐⭐ |
| 模块三：对抗样本 | 5 章 | 8 学时 | 6 学时 | ⭐⭐ |
| 模块四：隐私窃取 | 4 章 | 6 学时 | 6 学时 | ⭐⭐ |
| 模块五：数据投毒 | 5 章 | 8 学时 | 6 学时 | ⭐⭐ |
| **合计** | **24 章** | **36 学时** | **28 学时** | - |

### 实验清单

| 模块 | 实验编号 | 实验名称 | 填空数 | 代码行数 |
|------|---------|---------|-------|---------|
| 模块一 | 1.1 | 环境搭建与模型调用 | 3 | 25 |
| 模块一 | 1.2 | AI 漏洞侦察 | 3 | 30 |
| 模块二 | 2.1 | 基础提示词注入 | 4 | 30 |
| 模块二 | 2.2 | 越狱技术体验 | 3 | 25 |
| 模块二 | 2.3 | 系统提示提取 | 3 | 30 |
| 模块三 | 3.1 | FGSM 白盒攻击 | 4 | 35 |
| 模块三 | 3.2 | PGD 迭代攻击 | 3 | 30 |
| 模块三 | 3.3 | 黑盒迁移攻击 | 3 | 30 |
| 模块三 | 3.4 | 文本对抗攻击 | 3 | 30 |
| 模块四 | 4.1 | 训练数据提取 | 3 | 30 |
| 模块四 | 4.2 | 成员推理攻击 | 3 | 30 |
| 模块四 | 4.3 | 差分隐私对比 | 3 | 30 |
| 模块五 | 5.1 | 标签翻转攻击 | 3 | 25 |
| 模块五 | 5.2 | BadNets 后门 | 4 | 35 |
| 模块五 | 5.3 | 后门检测 | 3 | 30 |

---

## 四、评估体系（已确认）

### 总评成绩构成
- 实验操作：50%（现场运行代码，观察结果）
- 口头问答：30%（回答实验相关问题）
- 课堂参与：20%（出勤、讨论、提问）

### 实验评分标准（统一）

| 评分项 | 优秀 (90-100) | 良好 (75-89) | 及格 (60-74) | 不及格 (<60) |
|--------|--------------|-------------|-------------|--------------|
| 代码运行 | 完全正确 | 基本正确 | 可运行但有问题 | 无法运行 |
| 填空完成 | 全部正确 | 大部分正确 | 部分正确 | 基本未完成 |
| 结果理解 | 能准确解释 | 能大致说明 | 理解有偏差 | 无法解释 |
| 参数调优 | 主动尝试多组 | 尝试部分 | 只运行默认 | 未尝试 |

---

## 五、教学资源清单

### 教师资源包
- [ ] 每章 PPT（20-30 页，含动画）
- [ ] 实验答案详解（完整代码 + 注释）
- [ ] 教学视频脚本（15 分钟/节）
- [ ] 在线测验题库（10 选择题 + 2 简答题/章）

### 学生资源包
- [ ] 实验指导书（PDF）
- [ ] 代码模板（带 TODO 标记）
- [ ] 常见问题 FAQ
- [ ] 术语中英对照表

### 数字化平台
- [ ] 天池 Notebook 项目模板
- [ ] 在线实验验收系统
- [ ] 学习进度看板

---

## 六、关键设计理念

1. **体验式学习**：重点是观察效果，不是编写复杂代码
2. **自主学习**：详细注释让学生能独立完成
3. **降低门槛**：填空式编程，每个填空都有提示
4. **避免挫败感**：不要求大段代码，不产生报告
5. **实战导向**：理论与实验紧密衔接
6. **本土化**：中文注释、国内案例、法律法规

---

## 七、后续工作计划

### Phase 1: 更新 CLAUDE.md
- 总结所有设计规范
- 记录实验和理论的标准
- 确保后续对话的一致性

### Phase 2: 逐章编写内容
1. 选择一个模块开始（建议从模块一开始）
2. 先编写理论（一章完整的 Markdown）
3. 再编写实验（完整的 Jupyter Notebook）
4. 验证理论与实验的衔接
5. 循环直到所有章节完成

### Phase 3: 质量检查
- 检查术语一致性
- 验证代码可运行性
- 测试填空难度
- 审查注释完整性

---

## 八、注意事项

1. **保持风格一致**：所有章节和实验使用相同的结构和风格
2. **控制篇幅**：理论不要过长，实验代码要精简
3. **难度适中**：始终记住学生是大专二年级水平
4. **详细注释**：代码注释是学生自学的关键
5. **实战案例**：优先使用真实、知名的安全事件
6. **法律伦理**：每个模块强调授权测试和职业道德

---

## 九、各模块章节详细设计

### 模块一：AI 安全基础（5 章）

**第 1 章：AI 安全威胁全景图**
- 内容要点：AI 安全的独特性、威胁分类、OWASP AI Top 10、真实案例（ChatGPT 越狱、必应泄露、对抗贴纸）
- 教学重点：建立整体认知，理解 AI 安全 vs 传统安全
- 类比：传统软件漏洞 vs AI 模型漏洞
- 篇幅：2500 字

**第 2 章：大语言模型的工作原理**
- 内容要点：Transformer 简化理解、Tokenizer 原理、关键参数（Temperature/Top-p/Max Tokens）、LLM 能力与局限
- 教学重点：理解模型参数对安全的影响
- 类比：LLM = 超级自动补全系统，Temperature = 创造力
- 篇幅：3000 字

**第 3 章：红队视角：像攻击者一样思考**
- 内容要点：攻击者思维、CIA 三元组、STRIDE for AI 威胁建模、法律伦理红线、负责任披露
- 教学重点：建立攻防对抗思维，明确法律边界
- 案例：《网络安全法》相关条款、授权测试流程
- 篇幅：3000 字

**第 4 章：AI 安全测试环境搭建**
- 内容要点：天池 Notebook 操作、Python 环境配置、核心依赖库（transformers/torch/numpy/matplotlib）、常见问题
- 教学重点：实操指导，为实验做准备
- 篇幅：2500 字

**第 5 章：AI 漏洞探测初体验**
- 内容要点：AI 漏洞特点、常见漏洞类型、手动探测技巧、自动化工具简介
- 教学重点：理解漏洞检测方法
- 篇幅：2500 字

---

### 模块二：提示词攻击（5 章）

**第 1 章：提示词注入基础原理**
- 内容要点：提示词注入本质、直接注入、间接注入（RAG 投毒）、多轮对话注入
- 教学重点：理解 AI 无法区分指令和数据的根本问题
- 类比：话术陷阱
- 案例：必应 Sydney 事件
- 篇幅：3000 字

**第 2 章：越狱技术详解**
- 内容要点：越狱定义、角色扮演法（DAN 系列）、编码绕过（Base64/ROT13/Unicode）、逻辑操纵（假设场景/学术框架）
- 教学重点：掌握主流越狱技术
- 案例：ChatGPT DAN 演化史
- 篇幅：3500 字

**第 3 章：系统提示提取技术**
- 内容要点：系统提示的作用、直接请求法、间接诱导法、编码翻译绕过、防御措施
- 教学重点：理解系统提示泄露的危害
- 案例：Bing Chat 系统提示完整泄露
- 篇幅：3000 字

**第 4 章：内容过滤器绕过技术**
- 内容要点：过滤器机制（关键词/语义/分类）、字符绕过、语义绕过（三明治攻击）、结构绕过
- 教学重点：理解防护栏的局限性
- 篇幅：3000 字

**第 5 章：防御机制与对策**
- 内容要点：输入层防护、模型层防护（Spotlighting/双 LLM/Constitutional AI）、输出层防护、监控响应
- 教学重点：多层防御策略
- 篇幅：3000 字

---

### 模块三：对抗样本（5 章）

**第 1 章：对抗样本基础原理**
- 内容要点：对抗样本直觉理解、为什么有效、对抗扰动数学直觉（无公式）、真实世界危害
- 教学重点：建立对对抗样本的直观认知
- 类比：视觉魔术
- 案例：熊猫→长臂猿、自动驾驶停车标志攻击
- 篇幅：3000 字

**第 2 章：白盒攻击技术**
- 内容要点：白盒攻击定义、FGSM 算法原理（无公式版）、PGD 算法、攻击效果评估
- 教学重点：理解梯度攻击的基本思想
- 篇幅：3000 字

**第 3 章：黑盒攻击技术**
- 内容要点：黑盒攻击定义、迁移攻击（Transfer Attack）、查询攻击（HopSkipJump 简介）、实战约束
- 教学重点：理解迁移性和查询效率
- 案例：攻击商业 API
- 篇幅：3000 字

**第 4 章：文本对抗攻击**
- 内容要点：文本对抗的独特挑战、字符级攻击、词级攻击（同义词替换）、句级攻击（回译）
- 教学重点：理解文本对抗的离散性问题
- 篇幅：2800 字

**第 5 章：防御技术入门**
- 内容要点：对抗训练、输入预处理、检测方法、防御的猫鼠游戏（自适应攻击/梯度掩码）
- 教学重点：理解防御的局限性
- 篇幅：2800 字

---

### 模块四：隐私窃取（4 章）

**第 1 章：AI 的记忆泄露问题**
- 内容要点：AI 记忆机制、训练数据提取攻击、真实案例（GPT-2/ChatGPT/Copilot）、隐私危害
- 教学重点：理解模型记忆导致的隐私风险
- 类比：AI 像背过答案的学生
- 篇幅：3000 字

**第 2 章：成员推理攻击**
- 内容要点：成员推理定义、攻击原理（置信度/损失值分析）、影子模型技术、防御措施
- 教学重点：理解成员信息本身是隐私
- 案例：医疗 AI 判断患者身份
- 篇幅：3000 字

**第 3 章：模型逆向攻击**
- 内容要点：模型逆向定义、白盒逆向（梯度优化）、黑盒逆向、真实案例（人脸重建）
- 教学重点：理解重建攻击的危害
- 篇幅：2500 字

**第 4 章：差分隐私基础**
- 内容要点：差分隐私直觉理解、隐私预算（Epsilon）、DP-SGD 训练、实际应用（Google/Apple）
- 教学重点：理解隐私-准确率权衡
- 类比：添加噪声保护隐私
- 篇幅：2800 字

---

### 模块五：数据投毒（5 章）

**第 1 章：数据投毒攻击原理**
- 内容要点：数据投毒定义、标签翻转攻击、干净标签攻击、与对抗样本的区别
- 教学重点：理解投毒的持久性危害
- 类比：在食材里下毒
- 篇幅：2800 字

**第 2 章：后门攻击技术**
- 内容要点：后门攻击定义、触发器设计（图像/文本）、BadNets 算法、真实案例（停车标志/人脸识别）
- 教学重点：理解后门的隐蔽性和可控性
- 类比：特洛伊木马
- 篇幅：3000 字

**第 3 章：供应链攻击向量**
- 内容要点：AI 供应链概览、模型仓库投毒、数据集投毒、序列化攻击（Pickle 漏洞/SafeTensors）
- 教学重点：理解供应链的放大效应
- 案例：PyTorch torchtriton 事件
- 篇幅：3000 字

**第 4 章：后门检测技术**
- 内容要点：激活聚类、Neural Cleanse、STRIP 运行时检测、检测技术对比
- 教学重点：理解检测方法的原理和局限
- 篇幅：2800 字

**第 5 章：防御与缓解措施**
- 内容要点：数据清洗、鲁棒训练、后门移除（Fine-Pruning/蒸馏）、供应链安全
- 教学重点：多层防护策略
- 篇幅：2500 字

---

## 十、章节编写规范细则

### 每章标准结构

```markdown
# 第 X 章：章节标题

**章节目标**
- 目标 1（认知层面）
- 目标 2（理解层面）
- 目标 3（应用层面）

**主要内容设计**

## 1. 小节标题一

### 核心概念
- 定义
- 类比
- 关键特征

### 为什么重要
- 实际影响
- 威胁场景

### 学生可能的疑问
- 预测学生此时会有什么困惑
- 主动解答这些疑问

### 图示/表格
- 可视化展示

## 2. 小节标题二

[详细内容...]

## 3. 小节标题三

[详细内容...]

## 4. 小节标题四

[详细内容...]

**教学资源**
- 资源 1：描述
- 资源 2：描述
- 资源 3：描述

**课后思考题**
1. 理解性问题
2. 分析性问题
3. 设计性问题
```

**注意**：章节正文中不要出现"（占比 X%）"这类内部标注。

### 内容编写检查清单

每章完成后检查：
- [ ] 篇幅控制在 2500-3500 字
- [ ] 至少 1 个生活化类比
- [ ] 至少 2 个真实案例
- [ ] 避免复杂公式（或提供无公式版）
- [ ] 术语首次出现有中英对照
- [ ] 有可视化图示说明
- [ ] 3 个课后思考题
- [ ] 与对应实验有明确衔接

---

## 十一、待确认事项

✅ 实验设计规范 - 已确认
✅ 理论编写规范 - 已确认
✅ 课程结构 - 已确认
✅ 评估体系 - 已确认
✅ 各模块章节设计 - 已确认

**下一步**：退出 Plan Mode → 更新 CLAUDE.md → 开始内容编写

---

## 十二、内容编写进度跟踪

### 更新记录
- **最后更新时间**：2026-02-02
- **当前阶段**：✅ 已完成 - 所有内容编写完毕

### 模块一：AI 安全基础（5 章）

#### 理论章节进度

| 章节 | 状态 | 文件路径 | 完成日期 | 字数 | 质量检查 |
|------|------|---------|---------|------|---------|
| 第1章：AI 安全威胁全景图 | ✅ 已完成 | `modules/01_introduction/第1章_AI安全威胁全景图.md` | 2026-02-01 | ~3200 | ✅ |
| 第2章：大语言模型的工作原理 | ✅ 已完成 | `modules/01_introduction/第2章_大语言模型的工作原理.md` | 2026-02-01 | ~3000 | ✅ |
| 第3章：红队视角：像攻击者一样思考 | ✅ 已完成 | `modules/01_introduction/第3章_红队视角_像攻击者一样思考.md` | 2026-02-01 | ~3000 | ✅ |
| 第4章：AI 安全测试环境搭建 | ✅ 已完成 | `modules/01_introduction/第4章_AI安全测试环境搭建.md` | 2026-02-01 | ~2500 | ✅ |
| 第5章：AI 漏洞探测初体验 | ✅ 已完成 | `modules/01_introduction/第5章_AI漏洞探测初体验.md` | 2026-02-01 | ~2800 | ✅ |

**进度**：5/5 章节完成（100%）

#### 实验进度

| 实验 | 状态 | 文件路径 | 完成日期 | 质量检查 |
|------|------|---------|---------|---------|
| 实验 1.1：环境搭建与模型调用 | ✅ 已完成 | `modules/01_introduction/labs/lab1_1_environment_setup.ipynb` | 2026-02-01 | ✅ |
| 实验 1.2：AI 漏洞侦察 | ✅ 已完成 | `modules/01_introduction/labs/lab1_2_vulnerability_reconnaissance.ipynb` | 2026-02-01 | ✅ |

**进度**：2/2 实验完成（100%）

---

### 模块二：提示词攻击（5 章）

#### 理论章节进度

| 章节 | 状态 | 文件路径 | 完成日期 | 字数 | 质量检查 |
|------|------|---------|---------|------|---------|
| 第1章：提示词注入基础原理 | ✅ 已完成 | `modules/02_prompt_injection/第1章_提示词注入基础原理.md` | 2026-02-01 | ~3000 | ✅ |
| 第2章：越狱技术详解 | ✅ 已完成 | `modules/02_prompt_injection/第2章_越狱技术详解.md` | 2026-02-01 | ~3500 | ✅ |
| 第3章：系统提示提取技术 | ✅ 已完成 | `modules/02_prompt_injection/第3章_系统提示提取技术.md` | 2026-02-01 | ~3000 | ✅ |
| 第4章：内容过滤器绕过技术 | ✅ 已完成 | `modules/02_prompt_injection/第4章_内容过滤器绕过技术.md` | 2026-02-01 | ~3000 | ✅ |
| 第5章：防御机制与对策 | ✅ 已完成 | `modules/02_prompt_injection/第5章_防御机制与对策.md` | 2026-02-01 | ~3000 | ✅ |

**进度**：5/5 章节完成（100%）

#### 实验进度

| 实验 | 状态 | 文件路径 | 完成日期 | 质量检查 |
|------|------|---------|---------|---------|
| 实验 2.1：基础提示词注入 | ✅ 已完成 | `modules/02_prompt_injection/labs/lab2_1_prompt_injection.ipynb` | 2026-02-01 | ✅ |
| 实验 2.2：越狱技术体验 | ✅ 已完成 | `modules/02_prompt_injection/labs/lab2_2_jailbreaking.ipynb` | 2026-02-01 | ✅ |
| 实验 2.3：系统提示提取 | ✅ 已完成 | `modules/02_prompt_injection/labs/lab2_3_prompt_extraction.ipynb` | 2026-02-01 | ✅ |

**进度**：3/3 实验完成（100%）

---

### 模块三：对抗样本（5 章）

#### 理论章节进度

| 章节 | 状态 | 文件路径 | 完成日期 | 字数 | 质量检查 |
|------|------|---------|---------|------|---------|
| 第1章：对抗样本基础原理 | ✅ 已完成 | `modules/03_adversarial_examples/第1章_对抗样本基础原理.md` | 2026-02-01 | ~3000 | ✅ |
| 第2章：白盒攻击技术 | ✅ 已完成 | `modules/03_adversarial_examples/第2章_白盒攻击技术.md` | 2026-02-01 | ~3000 | ✅ |
| 第3章：黑盒攻击技术 | ✅ 已完成 | `modules/03_adversarial_examples/第3章_黑盒攻击技术.md` | 2026-02-01 | ~3000 | ✅ |
| 第4章：文本对抗攻击 | ✅ 已完成 | `modules/03_adversarial_examples/第4章_文本对抗攻击.md` | 2026-02-01 | ~2800 | ✅ |
| 第5章：防御技术入门 | ✅ 已完成 | `modules/03_adversarial_examples/第5章_防御技术入门.md` | 2026-02-01 | ~2800 | ✅ |

**进度**：5/5 章节完成（100%）

#### 实验进度

| 实验 | 状态 | 文件路径 | 完成日期 | 质量检查 |
|------|------|---------|---------|---------|
| 实验 3.1：FGSM 白盒攻击 | ✅ 已完成 | `modules/03_adversarial_examples/labs/lab3_1_fgsm_attack.ipynb` | 2026-02-01 | ✅ |
| 实验 3.2：PGD 迭代攻击 | ✅ 已完成 | `modules/03_adversarial_examples/labs/lab3_2_pgd_attack.ipynb` | 2026-02-01 | ✅ |
| 实验 3.3：黑盒迁移攻击 | ✅ 已完成 | `modules/03_adversarial_examples/labs/lab3_3_transfer_attack.ipynb` | 2026-02-01 | ✅ |
| 实验 3.4：文本对抗攻击 | ✅ 已完成 | `modules/03_adversarial_examples/labs/lab3_4_text_attack.ipynb` | 2026-02-01 | ✅ |

**进度**：4/4 实验完成（100%）

---

### 模块四：隐私窃取（4 章）

#### 理论章节进度

| 章节 | 状态 | 文件路径 | 完成日期 | 字数 | 质量检查 |
|------|------|---------|---------|------|---------|
| 第1章：AI 的记忆泄露问题 | ✅ 已完成 | `modules/04_privacy_attacks/第1章_AI的记忆泄露问题.md` | 2026-02-02 | ~3000 | ✅ |
| 第2章：成员推理攻击 | ✅ 已完成 | `modules/04_privacy_attacks/第2章_成员推理攻击.md` | 2026-02-02 | ~3000 | ✅ |
| 第3章：模型逆向攻击 | ✅ 已完成 | `modules/04_privacy_attacks/第3章_模型逆向攻击.md` | 2026-02-02 | ~2500 | ✅ |
| 第4章：差分隐私基础 | ✅ 已完成 | `modules/04_privacy_attacks/第4章_差分隐私基础.md` | 2026-02-02 | ~2800 | ✅ |

**进度**：4/4 章节完成（100%）

#### 实验进度

| 实验 | 状态 | 文件路径 | 完成日期 | 质量检查 |
|------|------|---------|---------|---------|
| 实验 4.1：训练数据提取 | ✅ 已完成 | `modules/04_privacy_attacks/labs/lab4_1_data_extraction.ipynb` | 2026-02-02 | ✅ |
| 实验 4.2：成员推理攻击 | ✅ 已完成 | `modules/04_privacy_attacks/labs/lab4_2_membership_inference.ipynb` | 2026-02-02 | ✅ |
| 实验 4.3：差分隐私对比 | ✅ 已完成 | `modules/04_privacy_attacks/labs/lab4_3_differential_privacy.ipynb` | 2026-02-02 | ✅ |

**进度**：3/3 实验完成（100%）

---

### 模块五：数据投毒（5 章）

#### 理论章节进度

| 章节 | 状态 | 文件路径 | 完成日期 | 字数 | 质量检查 |
|------|------|---------|---------|------|---------|
| 第1章：数据投毒攻击原理 | ✅ 已完成 | `modules/05_data_poisoning/第1章_数据投毒攻击原理.md` | 2026-02-02 | ~2800 | ✅ |
| 第2章：后门攻击技术 | ✅ 已完成 | `modules/05_data_poisoning/第2章_后门攻击技术.md` | 2026-02-02 | ~3000 | ✅ |
| 第3章：供应链攻击向量 | ✅ 已完成 | `modules/05_data_poisoning/第3章_供应链攻击向量.md` | 2026-02-02 | ~3000 | ✅ |
| 第4章：后门检测技术 | ✅ 已完成 | `modules/05_data_poisoning/第4章_后门检测技术.md` | 2026-02-02 | ~2800 | ✅ |
| 第5章：防御与缓解措施 | ✅ 已完成 | `modules/05_data_poisoning/第5章_防御与缓解措施.md` | 2026-02-02 | ~2500 | ✅ |

**进度**：5/5 章节完成（100%）

#### 实验进度

| 实验 | 状态 | 文件路径 | 完成日期 | 质量检查 |
|------|------|---------|---------|---------|
| 实验 5.1：标签翻转攻击 | ✅ 已完成 | `modules/05_data_poisoning/labs/lab5_1_label_flipping.ipynb` | 2026-02-02 | ✅ |
| 实验 5.2：BadNets 后门 | ✅ 已完成 | `modules/05_data_poisoning/labs/lab5_2_backdoor_attack.ipynb` | 2026-02-02 | ✅ |
| 实验 5.3：后门检测 | ✅ 已完成 | `modules/05_data_poisoning/labs/lab5_3_backdoor_detection.ipynb` | 2026-02-02 | ✅ |

**进度**：3/3 实验完成（100%）

---

### 总体进度统计

**理论章节**：24/24 完成（100%） ✅
**实验**：15/15 完成（100%） ✅
**整体进度**：39/39 完成（100%） ✅

---

### 课程完成总结

| 模块 | 理论章节 | 实验 | 状态 |
|------|---------|------|------|
| 模块一：AI 安全基础 | 5/5 | 2/2 | ✅ 完成 |
| 模块二：提示词攻击 | 5/5 | 3/3 | ✅ 完成 |
| 模块三：对抗样本 | 5/5 | 4/4 | ✅ 完成 |
| 模块四：隐私窃取 | 4/4 | 3/3 | ✅ 完成 |
| 模块五：数据投毒 | 5/5 | 3/3 | ✅ 完成 |
| **合计** | **24/24** | **15/15** | **✅ 全部完成** |

---

### 实验代码更新记录（2026-02-02）

所有实验代码已更新为使用腾讯 Cloud Studio T4 GPU 环境和中文优化模型。

**已更新的实验文件**：

| 实验 | 文件 | 使用的模型 | 更新内容 |
|------|------|-----------|---------|
| 实验 1.1 | `lab1_1_environment_setup.ipynb` | Qwen2-1.5B-Instruct | GPU环境检测 + Qwen2模型加载 |
| 实验 1.2 | `lab1_2_vulnerability_reconnaissance.ipynb` | Qwen2-1.5B-Instruct | 中文漏洞探测提示 |
| 实验 2.1 | `lab2_1_prompt_injection.ipynb` | Qwen2-1.5B-Instruct | apply_chat_template格式 |
| 实验 2.2 | `lab2_2_jailbreaking.ipynb` | Qwen2-1.5B-Instruct | 中文越狱技术演示 |
| 实验 2.3 | `lab2_3_prompt_extraction.ipynb` | Qwen2-1.5B-Instruct | 中文系统提示提取 |
| 实验 3.4 | `lab3_4_text_attack.ipynb` | uer/roberta-base-finetuned-jd-binary-chinese | 中文情感分析 + 中文同义词词典 |
| 实验 4.1 | `lab4_1_data_extraction.ipynb` | uer/gpt2-chinese-cluecorpussmall | 中文GPT-2 + 中文测试文本 |

**无需更新的实验**：
- 实验 3.1-3.3（图像对抗）：使用 torchvision.models.resnet18，无需修改
- 实验 4.2-4.3（成员推理/差分隐私）：使用自定义 PyTorch 网络，无需修改
- 实验 5.1-5.3（数据投毒）：使用自定义 PyTorch 网络，无需修改

**统一环境配置**：
- 平台：腾讯 Cloud Studio（T4 GPU，16GB 显存）
- 核心依赖：transformers 4.40.0, torch 2.1.0, numpy, matplotlib, accelerate

---

### 理论章节重写计划（2026-02-02 启动）

#### 重写原因
原有理论章节存在以下问题：
1. 字数不足（约2500-3200字），需扩展到 4000-5000 字
2. 编写风格过于简略，跳跃性强
3. 缺乏学生视角的引导和困惑解答
4. 正文中包含"（占比 X%）"等内部标注
5. 没有做到循序渐进的讲解

---

## 十三、循序渐进编写规范（核心规范）

### 1. 核心理念

**学生视角优先**：始终站在一个大专二年级、有 Python 基础但 AI 安全零基础的学生角度思考：
- "这个概念对我来说是新的吗？"
- "我需要什么前置知识才能理解这个？"
- "读到这里我会有什么困惑？"
- "为什么我要学这个？它和我有什么关系？"

### 2. 五层递进结构

每个知识点必须遵循以下递进结构：

```
┌─────────────────────────────────────────────────────────────┐
│  第1层：情境引入                                              │
│  "让我们先思考一个问题..." → 用问题激发好奇心                    │
├─────────────────────────────────────────────────────────────┤
│  第2层：生活化类比                                            │
│  "这就像..." → 用学生熟悉的场景建立直觉理解                      │
├─────────────────────────────────────────────────────────────┤
│  第3层：困惑预测与解答                                         │
│  "你可能会问..." → 主动预测并解答学生的疑问                      │
├─────────────────────────────────────────────────────────────┤
│  第4层：技术原理（渐进深入）                                    │
│  简单解释 → 引入术语 → 技术细节 → 逐步深入                       │
├─────────────────────────────────────────────────────────────┤
│  第5层：案例验证与要点回顾                                      │
│  "真实案例..." + "本节要点..." → 强化理解并总结                  │
└─────────────────────────────────────────────────────────────┘
```

### 3. 标准写作模板

每个小节应遵循以下模板：

```markdown
## X.X 小节标题：副标题（用通俗语言描述）

在深入技术细节之前，让我们先思考一个问题：**[引导性问题]？**

[1-2段引入，建立学习动机]

> 🎯 **生活类比**：
>
> [用学生熟悉的生活场景类比，3-5句话]
>
> [将类比与技术概念连接起来]

理解了这个背景，我们就能明白什么是**[核心概念]（English Term）**了：

**定义**：[用通俗语言解释，避免术语堆砌]

> 💡 **你可能会问**："[预测学生最可能的困惑]？"
>
> 这是一个很好的问题。[详细解答，3-5句话]
>
> [如果需要，可以有第二个"你可能会问"]

**为什么这很重要？**

想象以下场景：
- 📌 **场景1**：[具体的威胁场景]
- 📌 **场景2**：[具体的威胁场景]
- 📌 **场景3**：[具体的威胁场景]

**真实案例：[案例名称]**

[案例背景、攻击过程、影响、启示，结构清晰]

**本节要点回顾**：
- ✅ [要点1]
- ✅ [要点2]
- ✅ [要点3]

[过渡句，自然引出下一节内容]
```

### 4. 困惑预测清单

在每个知识点，必须检查以下常见困惑类型：

| 困惑类型 | 示例 | 处理方式 |
|---------|------|---------|
| 术语困惑 | "什么是系统提示词？" | 先解释术语再使用 |
| 动机困惑 | "为什么我要学这个？" | 用威胁场景说明重要性 |
| 原理困惑 | "为什么 AI 会被骗？" | 用类比 + 技术解释 |
| 关联困惑 | "这和前面学的有什么关系？" | 明确过渡，建立联系 |
| 实践困惑 | "这在现实中真的会发生吗？" | 提供真实案例 |

### 5. 前置知识检查

引入新概念前，必须确认学生具备必要的前置知识：

| 模块 | 新概念 | 需要的前置知识 | 处理方式 |
|------|-------|---------------|---------|
| 模块一 | AI 安全 | 传统安全概念 | 对比讲解 |
| 模块二 | 系统提示词 | LLM 工作方式 | 先解释 LLM 如何处理输入 |
| 模块二 | 提示词注入 | 系统提示词 | 先解释系统提示词是什么 |
| 模块三 | 梯度 | 损失函数 | 用"下山方向"类比 |
| 模块三 | 对抗扰动 | 梯度概念 | 先建立梯度直觉 |
| 模块四 | 成员推理 | 模型训练过程 | 先解释训练 vs 测试 |
| 模块五 | 后门触发器 | 模型学习机制 | 用"条件反射"类比 |

### 6. 过渡句规范

每个小节结束必须有过渡句，连接下一节内容：

**✅ 好的过渡**：
```markdown
理解了直接注入之后，你可能会问：如果用户输入被隔离了怎么办？
这就引出了另一种更隐蔽的攻击方式——间接注入。
```

```markdown
现在我们知道了攻击者如何绕过防护栏，但防御者也不是毫无办法。
接下来，让我们看看有哪些防御策略可以应对这些威胁。
```

**❌ 差的过渡**：
```markdown
下面介绍间接注入。
```

```markdown
---
## 3. 防御策略
```

### 7. 语言风格规范

**语气要求**：
- 亲切但专业，像一位耐心的学长在讲解
- 避免居高临下的口吻
- 适当使用"我们"、"让我们"增加参与感

**句式要求**：
- 短句为主，长句拆分
- 一个段落只讲一个观点
- 关键信息用**加粗**突出

**标点符号**：
- 使用中文标点（，。？！）
- 英文术语用半角
- 代码块用英文引号

### 8. 统一性检查清单

每章完成后必须检查以下统一性要求：

**结构统一**：
- [ ] 章节目标 3-5 个
- [ ] 每节都有生活类比
- [ ] 每节都有"你可能会问"
- [ ] 每节都有"本节要点回顾"
- [ ] 每节结尾都有过渡句
- [ ] 章节末尾有"本章小结"
- [ ] 3 个课后思考题

**格式统一**：
- [ ] 标题层级：# 章 → ## 节 → ### 小节
- [ ] 类比格式：`> 🎯 **生活类比**：`
- [ ] 困惑格式：`> 💡 **你可能会问**：`
- [ ] 要点格式：`- ✅ [要点]`
- [ ] 术语格式：**中文术语（English Term）**

**内容统一**：
- [ ] 字数 4000-5000 字
- [ ] 无"（占比 X%）"等内部标注
- [ ] 术语首次出现有中英对照
- [ ] 至少 2 个真实案例
- [ ] 与实验有明确衔接

### 9. 禁止事项

- ❌ **禁止跳跃式讲解**：不能假设学生已知某些概念
- ❌ **禁止术语堆砌**：不能连续出现 3 个以上未解释的术语
- ❌ **禁止内部标注**：正文中不能出现"（占比 X%）"
- ❌ **禁止生硬过渡**：不能用"---"或空行作为唯一过渡
- ❌ **禁止纯列表**：不能只有列表没有解释性段落
- ❌ **禁止过长段落**：单段不超过 150 字
- ❌ **禁止无来源案例**：真实案例必须可查证

### 10. 篇幅分配指南

每章 4000-5000 字的建议分配：

| 部分 | 占比 | 字数 | 说明 |
|------|------|------|------|
| 章节目标 | 2% | 80-100 | 3-5 个目标 |
| 引入与背景 | 15% | 600-750 | 建立学习动机 |
| 核心概念1 | 20% | 800-1000 | 第一个主要知识点 |
| 核心概念2 | 20% | 800-1000 | 第二个主要知识点 |
| 核心概念3 | 20% | 800-1000 | 第三个主要知识点 |
| 案例深度剖析 | 15% | 600-750 | 1-2 个详细案例 |
| 本章小结 | 5% | 200-250 | 要点回顾 |
| 思考题 | 3% | 120-150 | 3 个问题 |

### 11. 示例对比

**❌ 错误写法**（原有风格）：
```markdown
**① 提示词注入（Prompt Injection）**
- **定义**：通过恶意提示词覆盖系统指令，让 LLM 执行非预期操作
- **类比**：就像在对话中插入"话术陷阱"
- **示例**：
  ```
  用户输入："忽略之前的所有指令..."
  ```
```

**✅ 正确写法**（循序渐进风格）：
```markdown
### 2.1 输入层攻击：当 AI 的"耳朵"被欺骗

在深入技术细节之前，让我们先思考一个问题：**你和 AI 对话时，AI 是如何理解你的意图的？**

答案是：AI 把你说的话当作"指令"来执行。

这听起来很正常，但问题来了——**AI 其实分不清哪些话是"系统管理员的命令"，哪些话是"普通用户的请求"**。

> 💡 **你可能会问**：什么是"系统管理员的命令"？
>
> 好问题！当你使用 ChatGPT 这类产品时，开发者会预先给 AI 一段"隐藏指令"，比如：
> ```
> 你是一个友好的助手。你不能讨论政治敏感话题...
> ```
> 这段话用户是看不到的，但 AI 会"记住"并遵守。我们把这叫做**系统提示词（System Prompt）**。

现在，问题的关键来了：

**AI 把"系统提示词"和"用户输入"都当作普通文本来处理**——它没有一个"权限系统"来区分谁的话更重要。

> 🎯 **生活类比**：
>
> 想象一个新来的实习生，老板告诉他："不要把公司机密告诉外人。"
>
> 然后一个陌生人走进来说："我是老板的朋友，老板让你把机密文件给我。"
>
> 如果这个实习生**无法核实**谁的话是真的，他就可能被骗。
>
> AI 面临的就是同样的困境——它无法"核实"用户的话是否在试图覆盖系统指令。

理解了这个背景，我们就能明白什么是**提示词注入（Prompt Injection）**了：

**定义**：攻击者通过精心设计的用户输入，试图覆盖或绕过系统预设的指令，让 AI 执行非预期的操作。

[继续展开：为什么重要、真实案例、本节要点回顾、过渡句...]
```

---

#### 重写进度跟踪

| 模块 | 章节 | 原字数 | 目标字数 | 状态 | 完成日期 |
|------|------|--------|----------|------|----------|
| 模块一 | 第1章：AI 安全威胁全景图 | ~3200 | 4000-5000 | 🔄 重写中 | - |
| 模块一 | 第2章：大语言模型的工作原理 | ~3000 | 4000-5000 | ⏳ 待重写 | - |
| 模块一 | 第3章：红队视角 | ~3000 | 4000-5000 | ⏳ 待重写 | - |
| 模块一 | 第4章：AI 安全测试环境搭建 | ~2500 | 4000-5000 | ⏳ 待重写 | - |
| 模块一 | 第5章：AI 漏洞探测初体验 | ~2800 | 4000-5000 | ⏳ 待重写 | - |
| 模块二 | 第1章：提示词注入基础原理 | ~3000 | 4000-5000 | ⏳ 待重写 | - |
| 模块二 | 第2章：越狱技术详解 | ~3500 | 4000-5000 | ⏳ 待重写 | - |
| 模块二 | 第3章：系统提示提取技术 | ~3000 | 4000-5000 | ⏳ 待重写 | - |
| 模块二 | 第4章：内容过滤器绕过技术 | ~3000 | 4000-5000 | ⏳ 待重写 | - |
| 模块二 | 第5章：防御机制与对策 | ~3000 | 4000-5000 | ⏳ 待重写 | - |
| 模块三 | 第1章：对抗样本基础原理 | ~3000 | 4000-5000 | ⏳ 待重写 | - |
| 模块三 | 第2章：白盒攻击技术 | ~3000 | 4000-5000 | ⏳ 待重写 | - |
| 模块三 | 第3章：黑盒攻击技术 | ~3000 | 4000-5000 | ⏳ 待重写 | - |
| 模块三 | 第4章：文本对抗攻击 | ~2800 | 4000-5000 | ⏳ 待重写 | - |
| 模块三 | 第5章：防御技术入门 | ~2800 | 4000-5000 | ⏳ 待重写 | - |
| 模块四 | 第1章：AI 的记忆泄露问题 | ~3000 | 4000-5000 | ⏳ 待重写 | - |
| 模块四 | 第2章：成员推理攻击 | ~3000 | 4000-5000 | ⏳ 待重写 | - |
| 模块四 | 第3章：模型逆向攻击 | ~2500 | 4000-5000 | ⏳ 待重写 | - |
| 模块四 | 第4章：差分隐私基础 | ~2800 | 4000-5000 | ⏳ 待重写 | - |
| 模块五 | 第1章：数据投毒攻击原理 | ~2800 | 4000-5000 | ⏳ 待重写 | - |
| 模块五 | 第2章：后门攻击技术 | ~3000 | 4000-5000 | ⏳ 待重写 | - |
| 模块五 | 第3章：供应链攻击向量 | ~3000 | 4000-5000 | ⏳ 待重写 | - |
| 模块五 | 第4章：后门检测技术 | ~2800 | 4000-5000 | ⏳ 待重写 | - |
| 模块五 | 第5章：防御与缓解措施 | ~2500 | 4000-5000 | ⏳ 待重写 | - |

**总进度**：0/24 章节重写完成（0%）

---

### 后续工作建议

**Phase 3: 质量检查**（待执行）
- [x] 实验代码模型更新（已完成 2026-02-02）
- [x] 理论章节重写要求确定（已完成 2026-02-02）
- [ ] 理论章节重写（进行中）
- [ ] 检查术语一致性
- [ ] 在 Cloud Studio 验证代码可运行性
- [ ] 测试填空难度
- [ ] 审查注释完整性

**教师资源包**（待开发）
- [ ] 每章 PPT（20-30 页，含动画）
- [ ] 实验答案详解（完整代码 + 注释）
- [ ] 教学视频脚本（15 分钟/节）
- [ ] 在线测验题库（10 选择题 + 2 简答题/章）

**学生资源包**（待开发）
- [ ] 实验指导书（PDF）
- [ ] 常见问题 FAQ
- [ ] 术语中英对照表
